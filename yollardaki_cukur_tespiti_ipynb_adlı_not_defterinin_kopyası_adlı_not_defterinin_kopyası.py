# -*- coding: utf-8 -*-
"""Yollardaki Cukur Tespiti.ipynb adl覺 not defterinin kopyas覺 adl覺 not defterinin kopyas覺

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g4sZf4x4MtQghedOFW4a8FcPmIP2_irW
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('drive')
# %cd /content/drive/MyDrive/ColabNotebooks/archive
!ls

import numpy as np
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from tensorflow import keras
from tensorflow.keras import layers
import seaborn as sns

for dirname, _, filenames in os.walk('/content/drive/MyDrive/ColabNotebooks/archive'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

plt.imshow(cv2.imread("/content/drive/MyDrive/ColabNotebooks/archive/potholes/68.jpg"))

plt.imshow(cv2.imread("/content/drive/MyDrive/ColabNotebooks/archive/normal/171.jpg"))

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True,
                                   validation_split=0.2)
training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/ColabNotebooks/archive',
                                                 target_size = (64, 64),
                                                 batch_size = 32,
                                                 class_mode = 'binary',
                                                 subset="training")

validation_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/ColabNotebooks/archive', 
                                                         target_size=(64, 64),
                                                         batch_size=32,
                                                         class_mode='binary',
                                                         subset='validation')

cnn = tf.keras.models.Sequential()
cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))
cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))
cnn.add(tf.keras.layers.Flatten())
cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))
cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

history = cnn.fit(x = training_set, validation_data = validation_generator, epochs = 50)

sns.set()
accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)

#accuracy plot
plt.plot(epochs, accuracy, color='b', label='Training Accuracy')
plt.plot(epochs, val_accuracy, color='r', label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.figure()

test_image = image.load_img('/content/drive/MyDrive/ColabNotebooks/archive/normal/306.jpg', target_size = (64, 64))
test_img = image.img_to_array(test_image)
test_img = np.expand_dims(test_img, axis = 0)
result = cnn.predict(test_img)
training_set.class_indices
if result[0][0] == 1:
  prediction = 'pothole'
else:
  prediction = 'normal'

print(prediction)
plt.imshow(test_image)

/content/drive/MyDrive/ColabNotebooks/archive/potholes/102.jpg
/content/drive/MyDrive/ColabNotebooks/archive/potholes/150.jpg
/content/drive/MyDrive/ColabNotebooks/archive/potholes/160.jpg
/content/drive/MyDrive/ColabNotebooks/archive/potholes/175.jpg
/content/drive/MyDrive/ColabNotebooks/archive/potholes/167.jpg